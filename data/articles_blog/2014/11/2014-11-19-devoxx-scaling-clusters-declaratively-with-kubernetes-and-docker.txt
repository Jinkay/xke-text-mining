2014-11-19-devoxx-scaling-clusters-declaratively-with-kubernetes-and-docker|Divers|   Cette année Docker est la technologie émergente. Beaucoup de présentations à Devoxx Anvers étaient consacrées à ce sujet et aux outils annexes. Parmi ces outils, nous avons un nouvel arrivant : Kubernetes et c’est Brian Dorsey de Google qui nous a présenté l’outil.  Le besoin Afin de mieux comprendre le besoin, Brian prend l’exemple d’une application avec un serveur Web, une base de données, un cache et des batchs. Chacun de ces composants va être sur des machines différentes. Afin de gérer, d’administrer et déployer ces machines, des outils tels que Chef, Puppet, Salt ou Ansible nous permettent d’adresser ces problématiques. Seulement cela demande du travail car de nombreux défis apparaissent :  Comment gérer les dépendances entre mes applications ? Comment scaler efficacement ? Comment gérer les mises à jour des différentes versions ? Comment gérer les déploiements et les rollbacks ?  Brian nous explique alors que la notion de conteneur avec Docker permet de répondre à ces différentes problématiques. En effet Docker permet l’isolation des processus au sein de son conteneur et les déploiements de ce dernier sont très rapides. Il nous confie que les conteneurs Docker sont massivement utilisés chez Google. Mais afin de gérer un parc de conteneur Docker, Google a réalisé une abstraction de ces conteneurs et a créé Kubernetes. Releasé en Mars 2014, Kubernetes a rapidement rencontré un grand succès. Voyez le nombre de contributeurs et de partenaires :  Comment fonctionne Kubernetes ?  Cet outil se base sur quatre principales notions :  Pods : ce sont des groupes de conteneurs Docker Labels : ce sont des clés/valeurs pour définir le rôle et l’environnement du pod (front-end, back-end, etc) Replication controller : s’assure que le nombre d’instance des pods définis est exécuté Services : agissent comme load balancer pour les pods  Brian passe ensuite à une démonstration de l’outil avec le déploiement de deux pods (chaque pod contient une application Web avec base de données et un système de cache). Les fichiers de configuration sont basés sur du Json et les informations a renseigner sont concises et simples. En quelques secondes, nous apercevons les deux pods déployés à travers une page Web listant ces derniers. Assez bluffant. Brian va plus loin et modifie le fichier de configuration pour déployer cinq pods. Le déploiement reste toujours de l’ordre de quelques secondes. Il nous montre ensuite la mise à jour des pods. Pour cela il modifie les pods pour pointer sur de nouveaux conteneurs Dockers et configure le fait que les mises à jour de chaque pod se fassent toute les huit secondes. Brian lance la mise à jour, et en direct, nous voyons les anciennes versions des pods s’éteindre et remplacées toute les huit secondes par les nouvelles. Kubernetes gère parfaitement et rapidement.Il nous montre également le comportement de Kubernetes en cas d’erreur sur un pod. Pour cela il tue un process Docker dans un pod. Ce dernier disparaît et Kubernetes va relancer le pod dans lequel était le conteneur défaillant. Brian termine sa présentation avec l’annonce de Google Container Engine qui permet d’exécuter Kubernetes et de provisionner des clusters rapidement. Encore en version Alpha, il nous met en garde sur le fait que l’outil n’est pas encore totalement stable. N’hésitez pas à suivre les évolutions de cet outil qui permet de bien orchestrer vos conteneurs Docker. 